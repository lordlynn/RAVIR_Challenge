# RAVIR Dataset Challenge

## Overview
The diagnosis and monitoring of systemic diseases, such as hypertension and diabetes, can be aided by examining retinal vasculature. The microvascular system is particularly relevant in such cases, and the retina is the only place where it can be directly observed. Assessing retinal vessels has been widely used as a proxy for systemic vascular diseases, and recent advances in retinal imaging and computer vision have renewed interest in this field. This project aimed to create a neural network that could segment grayscale images of retinal vasculature into three classes: background, artery, and vein. The algorithm employed an autoencoder architecture with skip connections that spanned across 4 resolutions and 3 kernels. Extensive data augmentation was also used to increase the breadth of the training data. The data was acquired through the Grand Challenge website and was tailored specifically for this purpose. The network was capable of segmenting images of retinal vasculature into three classes (background, artery, and veins) with no pre or post processing. The results achieved in this project did not meet or exceed the results of the currently used methods, however, they still proved that the algorithm could be a viable option if improved in the future. Some results were significantly better than others due to differences in test images. This project did serve its main purpose as a learning experience and introduction to machine learning with an emphasis on image processing. 

# Model Architecture
The methodology for this project closely resembles the methodology described in the RAVIR Dataset paper(https://arxiv.org/pdf/2203.14928), but diverges in certain aspects in order to simplify the architecture and downsize the network to be more manageable. The largest difference is that this version does not utilize the auxiliary decoder stream for regularization. The network was implemented in python3 using the Keras interface for TensorFlow. In order to decrease the required training time for networks, the Anaconda environment manager and CUDA tools were used to offload the training workload to a GTX 1070Ti graphics card.

The network architecture was an autoencoder that covered 4 different resolutions. The network leveraged skip connections from the encoder to the decoder in order to improve the training rate. Dropout layers were used after every convolution, but batch normalization was only used at the input layer, output layer, and in between the encoder and decoder. Relu activation was used for the first layer only, and softmax was used for the output layer; no other layers had activation functions.

![modelArc drawio](https://github.com/user-attachments/assets/a7fd716a-836e-47bf-a2ab-8edf5fc6db7c)

Each convolutional layer on the encoder side utilized a stride of (2,2) in order to reduce the resolution of the input image. Reducing the resolution helped to make the network size smaller and more manageable to train, as well as eliminating some noise in the output by extracting the largest features. On the decoder side, transposed convolution was used with a stride of (2,2) in order to scale the images back up to their original resolution. At the output of the decoder, an additional convolution layer at full resolution was used to learn the final feature classification.

# Loss Function
In line with the RAVIR Dataset paper(https://arxiv.org/pdf/2203.14928), a custom hybrid loss was employed. This loss was a 1:1 weighting of the categorical cross-entropy loss and the dice loss function. The dice loss function examines regional accuracy in an image while the categorical cross-entropy examines pixel-based accuracy, so the hybrid loss was meant to balance these factors.

# Data Augmentation
In order to help generalize and enhance the results of the network, extensive data augmentation was employed. The data augmentation was implemented using MATLAB due to the integration of image manipulation tools into the MATLAB environment and the familiarity with these tools from previous experience. The data augmentation process first normalized the input images using dynamic contrast stretching based on the histogram of each image. Then the seven nondestructive transforms were applied. Following this, five additional images with random global brightness changes were created by randomly selecting from the pool of previous images. Lastly, two images were blurred using a 5x5 neighborhood averaging filter.

# Results
The final model achieved a mean dice score of 0.63 but had some as high as 0.72 and as low as 0.52.

The RAVIR dataset by itself is not large enough to train a general segmentation network, but through the use of data augmentation the data set can be made to generalize fairly well. The RAVIR dataset was designed to include training data with variations in brightness, contrast, and blurring; so after augmentation, the training images are quite diverse. Although the result of this project is not nearly as good as the results achieved in the RAVIR research paper(https://arxiv.org/pdf/2203.14928), it did confirm that the RAVIR dataset and SEGRAVIR architectures are valid approaches to the problem. Lastly, this project served its main purpose as a learning experience and introduction to neural networks for image processing. 
